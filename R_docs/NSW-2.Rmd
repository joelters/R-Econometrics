---
title: "Treatment effects"
output:
  bookdown::html_document2:
    theme: yeti
    toc: true
    toc_float: true
bibliography: references.bib
---

\newcommand{\htau}{\widehat{\tau}}
\newcommand{\hmu}{\hat{\mu}}
\newcommand{\hp}{\widehat{p}}
\DeclareMathOperator{\E}{E}
\DeclareMathOperator{\PP}{P}
\newcommand{\p}[1]{\left( #1 \right)}

```{r, echo=FALSE, warning=FALSE}
# Deleting all current variables
rm(list=ls())
#this avoids scientific notation
# options(scipen = 999)

# Ensuring consistent random values in the bookdown version (this can be ignored).
set.seed(2, kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rejection")
```


# ATE I: Binary treatment

Source RMD file: [link](https://docs.google.com/uc?export=download&id=1WYFBGKPkG3y4lkTox_P7gG2Q6upEjbWd)


```{r, warning=FALSE, message=FALSE}
library(lmtest)
library(sandwich)
library(grf)
library(glmnet)
library(splines)
library(ggplot2)
library(reshape2)
library(devtools)
library(dplyr)
library(lmtest)
library(matlib)
library(ranger)
library(haven)
```


## Notation and definitions {#notation}

Let's establish some notation. Each data point will be defined by the triple $(X_i, D_i, Y_i)$. The vector $X_i$ represents covariates that are observed for individual $i$. Treatment assignment is indicated by $D_i \in \{0, 1\}$, with 1 representing treatment, and 0 representing control. The scalar $Y_i$ is the observed outcome, and it can be real or binary. Each observation is drawn independently and from the same distribution. We'll be interested in assessing the causal effect of treatment on outcome. 

A difficulty in estimating causal quantities is that we observe each individual in only one treatment state: either they were treated, or they weren't. However, it's often useful to imagine that each individual is endowed with two random variables $(Y_i(1), Y_i(0))$, where $Y_i(1)$ represents the value of this individual's outcome if they receive treatment, and $Y_i(0)$ represents their outcome if they are not treated. These random variables are called  **potential outcomes**. The observed outcome $Y_i$ corresponds to whichever potential outcome we got to see:
\begin{equation}
  Y_i \equiv Y_i(D_i) =
  \begin{cases}
    Y_i(1) \qquad \text{if }D_i = 1 \text{ (treated)} \\ 
    Y_i(0) \qquad \text{if }D_i = 0 \text{ (control)}\\ 
  \end{cases}
\end{equation}

Since we can't observe both $Y_i(1)$ and $Y_i(0)$, we won't be able to make statistical claims about the individual treatment effect $Y_i(1) - Y_i(0)$. Instead, our goal will be to estimate the **average treatment effect (ATE)**:
\begin{equation}
  (\#eq:ate)
  \tau := \E[Y_i(1) - Y_i(0)].
\end{equation}

Here, when we refer to the **randomized** setting we mean that we have data generated by a randomized control trial. The key characteristic of this setting is that the probability that an individual is assigned to the treatment arm is fixed. In particular, it does not depend on the individual's potential outcomes:
\begin{equation}
  (\#eq:unconf)
  Y_i(1), Y_i(0) \perp D_i.
\end{equation}
This precludes situations in which individuals may self-select into or out of treatment. The canonical failure example is a job training program in which workers enroll more often if they are more likely to benefit from treatment because in that case $D_i$ and $Y_i(1) - Y_i(0)$ would be positively correlated.

When condition \@ref(eq:unconf) is violated, we say that we are in an **observational** setting. This is a more complex setting encompassing several different scenarios: sometimes it's still possible to estimate the ATE under additional assumptions, sometimes the researcher can exploit other sources of variation to obtain other interesting estimands. Here, we will focus on ATE estimation under the following assumption:  
\begin{equation}
  (\#eq:cond-unconf)
  Y_i(1), Y_i(0) \perp D_i \ | \ X_i.
\end{equation}

In this document we will call this assumption **unconfoundeness**, though it is also known as **no unmeasured confounders**, **ignorability** or **selection on observables**. It says that all possible sources of self-selection, etc., can be explained by the observable covariates $X_i$. Continuing the example above, it may be that older or more educated are more likely to self-select into treatment; but when we compare two workers that have the same age and level of education, etc., there's nothing else that we could infer about their relative potential outcomes if we knew that one went into job training and the other did not.

As we'll see below, a key quantity of interest will be the treatment assignment probability, or **propensity score** $p(X_i) := \PP[W_i = 1 | X_i]$. In an experimental setting this quantity is usually known and fixed, and in observational settings it must be estimated from the data. We will often need to assume that the propensity score is bounded away from zero and one. That is, there exists some $\eta > 0$ such that
\begin{equation}
  (\#eq:overlap)
  \eta < p(x) < 1 - \eta  \qquad \text{for all }x.
\end{equation}
This assumption is known as **overlap**, and it means that for all types of people in our population (i.e., all values of observable characteristics) we can find some portion of individuals in treatment and some in control. Intuitively, this is necessary because we'd like to will be comparing treatment and control at each level of the covariates and then aggregate those results.

As a running example, we will use the National Supported Work (NSW) randomized experiment data used in the seminal paper by LaLonde (1986), see also Dehejia and Wahba (1999), where job training is assigned at random among a group of disadvantaged individuals. We also clean the workspace and load some packages we are going to need in this section (we download the package containing the data from github using devtools, check the link for more info). The data contains both a RCT and observational data. We analyze first the RCT....We are interested in real earnings in 1978 (re78) since in 1978 the program had already finished. Since this data is experimental we can directly estimate the ATE by looking at the difference in sample means $(W_i = 1)$, while the remaining half was asked about "assistance to the poor" $(W_i = 0)$. The outcome is binary, with $Y_i = 1$ corresponding to a positive answer. In the data set below, we also collect a few other demographic covariates.



```{r, message=FALSE, warning=FALSE}
# Read in data
setwd("C:/Users/Joel/Documents/CARLOS_III/PhD/Notes_slides_tutorials/R-Econometrics")
data_exp <- as_tibble(read_dta("Data/nsw_dw.dta"))
n <- nrow(data_exp)


# Treatment: job training participation (1) or not (0)
treatment <- "treat"

# Outcome: real earnings in 1978
outcome <- "re78"

# Additional covariates
covariates <- c("age", "education" , "black" , "hispanic" , "nodegree")
```


## Difference-in-means estimator {#diff-in-means}

Let's begin by considering a simple estimator that is available in experimental settings. The **difference-in-means** estimator is the sample average of outcomes in treatment minus the sample average of outcomes in control.
\begin{equation}
  (\#eq:ate-dm)
  \widehat{\tau}^{DIFF} =
    \frac{1}{n_1} \sum_{i:D_i = 1} Y_i -
    \frac{1}{n_0} \sum_{i:D_i = 0} Y_i
    \qquad \text{where} \qquad
    n_d := |\{i : d_i = d \}|
\end{equation}

Here’s one way to compute the difference-in-means estimator and its associated statistics (t-stats, p-values, etc.) directly:

```{r ate_dm}
# Only valid in the randomized setting. Do not use in observational settings.
Y <- data_exp[,outcome]
D <- data_exp[,treatment]
ate.est <- mean(Y[D==1]) - mean(Y[D==0])
ate.se <- sqrt(var(Y[D == 1]) / sum(D == 1) + var(Y[D == 0]) / sum(D == 0))
ate.tstat <- ate.est / ate.se
ate.pvalue <- 2*(pnorm(1 - abs(ate.est/ate.se)))
ate.results <- c(estimate=ate.est, std.error=ate.se, t.stat=ate.tstat, pvalue=ate.pvalue)
print(ate.results)
```

Or, alternatively, via the `t.test` function:
```{r ate_ttest}
fmla <- formula(paste(outcome, '~', treatment))  # y ~ w
t.test(fmla, data=data_exp)
```

We can also compute the same quantity via linear regression, using the fact that
\begin{equation}
  Y_i = Y_i(0) + W_i \left( Y_i(1) - Y_i(0) \right),
\end{equation}

so that taking expectations conditional on treatment assignment,
\begin{equation}
  \E[Y_i | D_i] = \alpha + D_i \tau \qquad \text{where} \qquad \alpha := \E[Y_i(0)]
\end{equation}

<font size=1>
[Exercise: make sure you understand this decomposition. Where is the unconfoundedness assumption \@ref(eq:unconf) used?]
</font>

This result implies that we can estimate the ATE of a binary treatment via a linear regression of observed outcomes $Y_i$ on a vector consisting of intercept and treatment assignment $(1, W_i)$.

```{r ate_ols_bad}
# Do not use! standard errors are not robust to heteroskedasticity! (See below)
fmla <- formula(paste0(outcome, '~', treatment))
ols <- lm(fmla, data=data_exp)
coef(summary(ols))[2,]
```
The point estimate we get is the same as we got above by computing the ATE "directly" via `mean(Y[D==1]) - mean(Y[D==0])`. However, the standard errors are different. This is because in `R` the command `lm` does not compute heteroskedasticity-robust standard errors. This is easily solvable.

```{r ate_old_good}
# Use this instead. Standard errors are heteroskedasticity-robust.
# Only valid in randomized setting.
fmla <- formula(paste0(outcome, '~', treatment))
ols <- lm(fmla, data=data_exp)
coeftest(ols, vcov=vcovHC(ols, type='HC2'))[2,]
```

The difference-in-means estimator is a simple, easily computable, unbiased, "model-free" estimator of the treatment effect. It should always be reported when dealing with experimental data. However, as we'll see later in this chapter, it may not necessarily be the one with smallest variance.

## Adjusting for covariates. Direct estimation

Our first estimator is suggested by the following decomposition of the ATE, which is possible due to unconfoundedness \@ref(eq:cond-unconf).

\begin{equation}
  \E[Y_i(1) - Y_i(0)]
  = \E[\E[Y_i | X_i, D_i=1]] - \E[\E[Y_i | X_i, D_i=0]]
\end{equation}

<font size=1>
[Exercise: make sure you understand this. Where is the unconfoundedness assumption used?]
</font>

The decomposition above suggests the following procedure, sometimes called the **direct estimate** of the ATE:

1. Estimate $\mu_{d}(x) := E[Y_i|X_i = x,D_i=d]$.
2. Predict $\hat{\mu}_{1}(X_i)$ and $\hat{\mu}_{0}(X_i)$ for each observation in the data.
3. Average out the predictions and subtract them.
\begin{equation}
  \htau^{DM} := \frac{1}{n} \sum_{i=1}^{n} \hmu_{1}(X_i) - \hmu_{0}(X_i)
\end{equation}


```{r ate_dm_bad, warning=FALSE}
# We'll see a better estimator below.

# Fitting some model of E[Y|X,D]
fmla <- as.formula(paste(outcome, "~ ", paste(covariates, "*", treatment, collapse="+")))
model <- lm(fmla, data=data_exp)  

# Predicting E[Y|X,D=d] for d in {0, 1}
data.1 <- data_exp
data.1[,treatment] <- 1
data.0 <- data_exp
data.0[,treatment] <- 0
muhat.treat <- predict(model, newdata=data.1)
muhat.ctrl <- predict(model, newdata=data.0)

# Averaging predictions and taking their difference
ate.est <- mean(muhat.treat) - mean(muhat.ctrl)
print(ate.est)
```

This estimator allows us to leverage regression techniques to estimate the ATE, so the resulting estimate should have smaller root-mean-squared error. However, it has several disadvantages that make it undesirable. First, its properties will rely heavily on the model  $\hmu_{d}(x)$ being correctly specified: it will be an unbiased and/or consistent estimate of the ATE provided that $\hmu_{d}(x)$  is an unbiased and/or consistent estimator of  $\E[Y|X=x, D=d]$. In practice, having a well-specified model is not something we want to rely upon. In general, it will also not be asymptotically normal, which means that we can’t easily compute t-statistics and p-values for it.


A technical note. Step 1 above can be done by regressing $Y_i$ on $X_i$ using only treated observations to get an estimate $\hat{\mu}_{1}(x)$ first, and then repeating the same to obtain $\hat{\mu}_{0}(x)$ from the control observations. Or it can be done by regression $Y_i$ on both covariates $(X_i, D_i)$ together and obtaining a function $\hat{\mu}_{d}(x)$. Both have advantages and disadvantages, and we refer to [Künzel, Sekhon, Bickel, Yu  (2019)](https://www.pnas.org/content/116/10/4156.short) for a discussion.

How do we compute s.e. for the previous estimator?

```{r ate_dm_good, warning=FALSE}
# LR without cross-fitting gives the previous estimator, but allows for easy computation of s.e.
p <- mean(D==1)
res1<-(Y-muhat.treat)*D
res0<-(Y-muhat.ctrl)*(1-D)
Z<-muhat.treat-muhat.ctrl+res1/p-res0/(1-p)
Z <- as.numeric(unlist(Z))
ateLR.est <- mean(Z)
ateLRsd.est <- sd(Z)/sqrt(n)
c("tauhatLR" = ateLR.est, "seLR" = ateLRsd.est)

```

## Inverse propensity-weighted estimator {#ipw}

The main idea in LaLonde (1986) is to replace the experimental control group with a control group which is taken from a survey. This means that we go from an experimental setting to an observational one (one where the potential outcomes cannot be expected to be independent from the treatment). The goal is to see whether observational methods can get near to the experimental estimates. To construct this database we keep only the treated from the experimental data and take as control the Current Population Survey (CPS).


```{r}
setwd("C:/Users/Joel/Documents/CARLOS_III/PhD/Notes_slides_tutorials/R-Econometrics")
psid_lalonde <- read_dta("Data/psid_controls.dta")
data_obs <- data_exp %>%
  filter(treat == 1) %>% 
  bind_rows(psid_lalonde) %>% 
  dplyr::select(-data_id)
```

We compute the direct estimator with the observational data

```{r, warning=FALSE}
# We'll see a better estimator below.

# Fitting some model of E[Y|X,D]
fmla <- as.formula(paste(outcome, "~ ", paste(covariates, "*", treatment, collapse="+")))
model <- lm(fmla, data=data_obs)  

# Predicting E[Y|X,D=d] for d in {0, 1}
data.1 <- data_obs
data.1[,treatment] <- 1
data.0 <- data_obs
data.0[,treatment] <- 0
muhat.treat <- predict(model, newdata=data.1)
muhat.ctrl <- predict(model, newdata=data.0)

# Averaging predictions and taking their difference
ate.est <- mean(muhat.treat) - mean(muhat.ctrl)
print(ate.est)
```
We see that the estimated ATE is very negative. This is because the treatment and the control are hardly comparable. The treatment is formed by disadvantaged individuals and the control by a representative sample of the US population. In the absence of treatment disadvantaged individuals would already have much lower earnings. 

We will use now the IPW estimator. Note that using unconfoundedness

$$
E[Y_i(1)] = E[E[Y_i | D_i = 1, X_i]] = \frac{E[E[Y_i D_i | X_i]]}{p(X_i)} = \frac{E[Y_i D_i]}{p(X_i)},
$$

meaning that we can estimate $E[Y_i(1)]$ with

\begin{equation}
  (\#eq:ipw-treated)
  \frac{n^{-1} \sum_{i=1}^n Y_i D_i}{\hat{p}(X_i)}.
\end{equation}

We must first estimate the assignment probability given some model, for example using logistic regression, forests, etc. With respect to modeling, the behavior of the IPW estimator is similar to the direct estimator: if $\hat{p}(X_i)$ is an unbiased estimate of $p(X_i)$, then \@ref(eq:ipw-treated) is an unbiased estimate of $E[Y(1)]$; and we can show that if $\hat{p}(X_i)$ is a consistent estimator of $p(X_i)$, then \@ref(eq:ipw-treated) is consistent for $E[Y(1)]$. 

Another important point is that when the estimated treatment propensity $\hat{p}(X_i)$ is small, the summands in \@ref(eq:ipw-treated) can be very large. In particular, if $\hat{p}(x)$ is exactly zero, then this estimator is undefined. That is why, in addition to requiring conditional unconfoundedness \@ref(eq:cond-unconf), it also requires the overlap condition \@ref(eq:overlap). In any case, when overlap is small (i.e., $\hat{p}(x)$ is very close to zero for many $x$), IPW becomes an unattractive estimator due to its high variance. We'll see in the next section an improved estimator that builds upon IPW but is strictly superior and should be used instead.

To visually check whether there are many observations concentrated near zero we can do a histogram of the propensity scores by treatment status. First we estimate the propensity score

```{r}
# Estimate the propensity score p(X) via logistic regression
fmla <- as.formula(paste0("~", paste0(covariates, collapse="+")))
D <- data_obs[,treatment]
Y <- data_obs[,outcome]
XX <- model.matrix(fmla, data_obs)
d <- as.numeric(unlist(D))
logit <- glm(d~XX, data=data_obs, family="binomial")
p.hat <- logit$fitted.values
data_obs$p.hat <- p.hat
```

and now we can do the histogram

```{r}
c1 <- rgb(173,216,230,max = 255, alpha = 180, names = "lt.blue")
c2 <- rgb(255,192,203, max = 255, alpha = 180, names = "lt.pink")

par(mar = c(5, 5, 5, 5) + 0.3)
hist(filter(data_obs, treat == 1)$p.hat, freq = TRUE, col = c1, axes = FALSE, xlab = "", ylab = "", main = "")
axis(side = 1, xlim = c(0,1))
axis(side = 4, ylab = "")
mtext(side = 4, text = "NSW", line = 2.5, col = "blue")
par(new=TRUE)
hist(filter(data_obs, treat == 0)$p.hat, ylim = c(0,2000), freq = TRUE, axes = FALSE, col = c2, xlab = "", ylab = "", main = "Common Support")
axis(side = 2)
mtext(side = 2, text = "CPS", line = 2.5, col = "pink")
```


We see that the control group (the CPS observations) are highly concentrated close to zero. This is because the NSW experiment chose disadvantaged individuals which are not representative of the US population as the CPS is. Hence, we have a comparability issue since those treated are very different from the control. A practical solution is to trim the observations with very low propensity scores. Of course, if we trim observation with a propensity score lower than 0.1, the concentration of propensity scores very close to zero disappears. 

````{r}
data_obs <- filter(data_obs, p.hat > 0.1)
# data_obs <- filter(data_obs, p.hat > min(data_obs$p.hat[data_obs$treat == 1]))

par(mar = c(5, 5, 5, 5) + 0.3)
hist(filter(data_obs, treat == 1)$p.hat, freq = TRUE, col = c1, axes = FALSE, xlab = "", ylab = "", main = "")
axis(side = 1, xlim = c(0,1))
axis(side = 4, ylab = "")
mtext(side = 4, text = "NSW", line = 2.5, col = "blue")
par(new=TRUE)
hist(filter(data_obs, treat == 0)$p.hat, freq = TRUE, axes = FALSE, col = c2, xlab = "", ylab = "", main = "Common Support")
axis(side = 2)
mtext(side = 2, text = "CPS", line = 2.5, col = "pink")
```

Let us keep the trimmed data

```` {r}
D <- data_obs[,treatment]
Y <- data_obs[,outcome]
p.hat <- data_obs$p.hat
```


Finally, we just derived an estimator of the average treated outcome, but we could repeat the argument for control units instead. Subtracting the two estimators leads to the following inverse propensity-weighted estimate of the treatment effect:
\begin{equation}
  (\#eq:ipw)
  \widehat{\tau}_1^{IPW} :=
  \frac{1}{n} \sum_{i=1}^{n} Y_i \frac{W_i}{\hp(X_i)}
  -
  \frac{1}{n} \sum_{i=1}^{n} Y_i \frac{(1 - W_i) }{1-\hp(X_i)}.
\end{equation}

The argument above suggests the following algorithm:

1. Estimate the propensity scores $p(X_i)$ by regressing $D_i$ on $X_i$. 
2. Compute the IPW estimator summand:
$$Z_i = Y_i \times \left(\frac{D_i}{\hat{p}(X_i)} - \frac{(1-D_i)}{(1-\hat{p}(X_i)} \right)$$ 
3. Compute the mean and standard error of the new variable $Z_i$

```{r}
# Available in randomized settings and observational settings with unconfoundedness+overlap

# Using the fact that
z <- Y * (D/p.hat - (1-D)/(1-p.hat))
z<-as.numeric(unlist(z))
ate.est <- mean(z)
ate.se <- sd(z) / sqrt(length(z))
ate.tstat <- ate.est / ate.se
ate.pvalue <- 2*(pnorm(1 - abs(ate.est/ate.se)))
ate.results <- c(estimate=ate.est, std.error=ate.se, t.stat=ate.tstat, pvalue=ate.pvalue)
print(ate.results)

```

Noting that $\mathbb{E}[D_i/p(X_i)] = 1$ by LIE and the same happens with $\mathbb{E}[(1-D_i)/(1-p(X_i))]$, an asymptotically equivalent estimator is

$$
\hat{\tau}^{IPW}_2 = \biggl(\sum_{i=1}^n \frac{D_i}{\hat{p}(X_i)}\biggr)^{-1} \biggl(\sum_{i=1}^n \frac{D_i Y_i}{\hat{p}(X_i)}\biggr) - \biggl(\sum_{i=1}^n \frac{1-D_i}{1-\hat{p}(X_i)}\biggr)^{-1} \biggl(\sum_{i=1}^n\frac{(1-D_i)Y_i}{1-\hat{p}(X_i)}\biggr)
$$

$\hat{\tau}^{IPW}_1$ and $\hat{\tau}^{IPW}_2$ are called Inverse Probability Weight (IPW) estimators and are a difference of weighted sums of $Y_i$. In $\hat{\tau}^{IPW}_2$ the weights sum up to $1$ and we have better finite sample properties. The algorithm for this estimator is the same as before but in step three we now compute the mean and standard deviation of

$$
\tilde{Z}_i = Y_i \times \biggl[\biggl(\sum_{i=1}^n \frac{D_i}{\hat{p}(X_i)}\biggr)^{-1} \frac{D_i}{\hat{p}(X_i)} - \biggl(\sum_{i=1}^n \frac{1-D_i}{1-\hat{p}(X_i)}\biggr)^{-1} \frac{1-D_i}{1 - \hat{p}(X_i)} \biggr]
$$

```{r}
z2 <- Y * ((1/(sum(D/p.hat)))*(D/p.hat) - (1/(sum((1-D)/(1-p.hat))))*((1-D)/(1-p.hat)))
z2 <- as.numeric(unlist(z2))
ate2.est <- mean(z2)
ate2.se <- sd(z2) / sqrt(length(z2))
ate2.tstat <- ate2.est / ate2.se
ate2.pvalue <- 2*(pnorm(1 - abs(ate2.est/ate2.se)))
ate2.results <- c(estimate=ate2.est, std.error=ate2.se, t.stat=ate2.tstat, pvalue=ate2.pvalue)
print(ate2.results)
```

In fact, both estimators are members of the broader class of consistent, semiparametric estimators found in [@robins1994estimation]. In this paper they find the estimator achieving the least asymptotic variance in this class to be none of the above but

$$
\hat{\tau}^{DR} = \frac{1}{n}\sum_{i=1}^n \frac{D_iY_i - \hat{\mu}_1(X_i)(D_i - \hat{p}(X_i))}{\hat{p}(X_i)} - \frac{1}{n}\sum_{i=1}^n \frac{(1-D_i)Y_i - \hat{\mu}_0(X_i)(D_i - \hat{p}(X_i))}{1 - \hat{p}(X_i)}, 
$$

This estimator is called Doubly robust because it has the attractive property that it is still consistent if $\mu_j$ $j = 0,1$, is incorrectly specified but the specification of the propensity score is correct. It is also consistent if the specification of the propensity score is not correct but that of $\mu_j$ is. This estimator is also called augmented IPW since it is "augmented" with the outcome regression. Now we are ready to do these estimations in R, we can just estimate the mean and standard deviation of

$$
Z^{DR}_i = Y_i \times \biggl[ \frac{D_i}{\hat{p}(X_i)} - \frac{1-D_i}{1-\hat{p}(X_i)} \biggr] + \frac{\hat{\mu}_0(X_i)(D_i - \hat{p}(X_i))}{1 - \hat{p}(X_i)} - \frac{\hat{\mu}_1(X_i)(D_i - \hat{p}(X_i))}{\hat{p}(X_i)}
$$

```{r}
# Doubly Robust
z.dr <- Y*(D/p.hat - (1-D)/(1-p.hat)) + muhat.ctrl*(D-p.hat)/(1-p.hat) - muhat.treat*(D-p.hat)/p.hat
z.dr <- as.numeric(unlist(z.dr))
atedr.est <- mean(z.dr)
atedr.se <- sd(z.dr) / sqrt(length(z.dr))
atedr.tstat <- atedr.est / atedr.se
atedr.pvalue <- 2*(pnorm(1 - abs(atedr.est/atedr.se)))
atedr.results <- c(estimate=atedr.est, std.error=atedr.se, t.stat=atedr.tstat, pvalue=atedr.pvalue)
print(atedr.results)
```

## Locally robust estimator

We can rewrite $\hat{\tau}^{DR}$ as

$$
\hat{\tau}^{DR} = \frac{1}{n}\sum_{i=1}^n \biggl( \hat{\mu}_1(X_i) - \hat{\mu}_0(X_i) + \frac{D_i}{\hat{p}(X_i)}[Y_i - \hat{\mu}_1(X_i)] -  \frac{1-D_i}{1 - \hat{p}(X_i)}[Y_i - \hat{\mu}_0(X_i)] \biggr).
$$

Note that this resembles the direct estimation of the ATE but with an added term, this term is a correction term which ensures local robustness. Let

$$
\psi(Z_i, p, \mu_1, \mu_0, \tau) = \mu_1(X_i) - \mu_0(X_i) + \underbrace{\frac{D_i}{p(X_i)}[Y_i - \mu_1(X_i)] -  \frac{(1-D_i)}{1 - p(X_i)}[Y_i - \mu_0(X_i)]}_{\phi(Z_i,p,\mu_1,\mu_0)} - \tau,
$$

and notice that $\hat{\tau}^{DR}$ is the $\tau$ which solves $\sum_{i=1}^n \psi(Z_i, \hat{p}, \hat{\mu}_1, \hat{\mu}_0, \tau) = 0$. The $\phi$ function is sometimes called the First Step Influence Function (FSIF, see [@chernozhukov2022locally]).It makes the orthogonal moment function locally robust by capturing the effect of first steps estimation. $\psi$ has a very special property: that of an orthogonal moment function. This means that, locally, estimating nuisance functions $p$, $\mu_1$ and $\mu_0$ has no impact. In fact we can even estimate them non-parametrically under mild rate conditions. Modifying slightly the estimator to estimate $p$, $\mu_1$ and $\mu_0$ with observations different from the ones we use to estimate $\tau_0$ (this is called cross-fitting) allows us to avoid over-fitting, use many non-parametric estimators such as machine learners, treat high dimensional cases and provide valid inference based only on the orthogonal moment function $\psi$. Hence, we define the locally robust IPW estimator as a cross-fitted version of the above. Partition the observations in $L$ sets denoted by $I_1,...,I_L$ and let $\hat{\mu}_{j,l}$ for $j = 0,1$, be an estimator of $\mu_j$ which does not use observations in partition $I_l$. Then 

$$
\hat{\tau}^{LR} = \frac{1}{n} \sum_{l=1}^L \sum_{i \in I_l} \biggl(\hat{\mu}_{1,l}(X_i) - \hat{\mu}_{0,l}(X_i) + \frac{D_i}{\hat{p}_l(X_i)}[Y_i - \hat{\mu}_{1,l}(X_i)] -  \frac{(1-D_i)}{1 - \hat{p}_l(X_i)}[Y_i - \hat{\mu}_{0,l}(X_i)] \biggr)
$$
Since this allows for general machine learners we are going to use random forests via the package ranger. We let $L=2$.

```{r}
set.seed(123)

fmlaD <- as.formula(paste0("treat~", paste0(covariates, collapse="+")))
fmlaY <- as.formula(paste0("re78~", paste0(covariates, collapse="+")))
XXD <- model.matrix(fmlaD, data_obs)
XXY <- model.matrix(fmlaY, data_obs)

n <- nrow(data_obs)
L <- 2
ind <- split(seq(n), seq(n) %% L)



fv1 <- rep(0,n)
fv0 <- rep(0,n)
ps <- rep(0,n)
for (i in 1:L){
  mps <- ranger(fmlaD, data = data_obs[ind[[i]],])
  mfv1 <- ranger(fmlaY, data = filter(data_obs[ind[[i]],], treat == 1))
  mfv0 <- ranger(fmlaY, data = filter(data_obs[ind[[i]],], treat == 0))
  
  fv1[-ind[[i]]] <- predict(mfv1, XXY[-ind[[i]],])$predictions
  fv0[-ind[[i]]] <- predict(mfv0, XXY[-ind[[i]],])$predictions
  ps[-ind[[i]]] <- predict(mps, XXD[-ind[[i]],])$predictions

}

z.lr <- fv1 - fv0 + (D/ps)*(Y-fv1) - ((1-D)/(1-ps))*(Y-fv0)
z.lr <- as.numeric(unlist(z.lr))
atelr.est <- mean(z.lr)
atelr.se <- sd(z.lr) / sqrt(length(z.lr))
atelr.tstat <- atelr.est / atelr.se
atelr.pvalue <- 2*(pnorm(1 - abs(atelr.est/atelr.se)))
atelr.results <- c(estimate=atelr.est, std.error=atelr.se, t.stat=atelr.tstat, pvalue=atelr.pvalue)
#this avoids scientific notation
options(scipen = 999)
print(atelr.results)

```

We still get a very negative effect. In general this data seems to be very ill suited for estimating treatment effects since the controls are wildly different from the treated.

## Packages and other sources

For a book on treatment effects one can read [@angrist2009mostly], for a reference on IPW  is a good reference is [@lunceford2004stratification]. The theory of the logistic regression is that of the conditional MLE and can be found for instance in [@wooldridge2002econometric]. A similar tutorial to this can be found [here](https://bookdown.org/halflearned/tutorial/ate1.html#aipw-estimators). Also, there are several packages with functions to perform the above estimation. An example of such a package is [PSweight](https://arxiv.org/pdf/2010.08893.pdf) in [@zhou2020psweight] where the package is compared to other similar packages.

# References

<div id="refs"></div>



